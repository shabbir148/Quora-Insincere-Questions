{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebram\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nimport re\nfrom wordcloud import WordCloud\nimport pickle\ntest_1 = pd.read_csv(\"../input/quora1/test.csv\")\ntrain_1=pd.read_csv(\"../input/quora1/train.csv\")\ntrain_c=train_1[\"question_text\"]\ntrain_c_y=train_1[\"target\"]\ntest_c=test_1[\"question_text\"]\nsample_train=list(train_c)\nsample_test=list(test_c)\nsub=pd.read_csv('../input/quora1/sample_submission.csv')\nsub.drop([\"target\"],axis=1)\ny=train_1['target'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nwith open(\"../input/dataset/embedding.txt\", \"rb\") as fp:   # Unpickling\n    embeddings = pickle.load(fp)\n    \n    \nwith open(\"../input/dataset/list_labels.txt\", \"rb\") as fp:   # Unpickling\n    list_labels = pickle.load(fp)    \n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y=train_c_y.to_list()\ntype(Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_set, test_set = train_test_split(train_1, test_size = 0.2, random_state = 1)\ntrain_set_q=train_set[\"question_text\"]\ntest_set_q=test_set[\"question_text\"]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_c = train_set.iloc[:,1:2].values\nY_train_c = train_set.iloc[:,2].values\nX_test_c = test_set.iloc[:,1:2].values\nY_test_c = test_set.iloc[:,2].values\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train_1.iloc[:,1].values\nY_train = train_1.iloc[:,2].values\nX_test = test_1.iloc[:,1].values\ntype(X_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of train data points:\",train_1.shape[0])\nprint(\"Number of test data points:\",test_1.shape[0])\nprint(\"Shape of Train Data:\", train_1.shape)\nprint(\"Shape of Test Data:\", test_1.shape)\ntest_1.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"For testing Number of train data points:\",train_set.shape[0])\nprint(\"For testing Number of test data points:\",test_set.shape[0])\nprint(\"For testing Shape of Train Data:\", train_set.shape)\nprint(\"For testing Shape of Test Data:\", test_set.shape)\ntrain_set.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Total sincere ans insincere questions\nfig_dims = (24, 12)\nfig, ax = plt.subplots(figsize=fig_dims)\nsns.countplot(train_1['target'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Percetage of insincere comments: \", round(train_1[\"target\"].mean()*100, 2))\nprint(\"Percetage of sincere comments: \", 100-round(train_1[\"target\"].mean()*100, 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\ndef remove_newline(text):\n    \"\"\"\n    remove \\n and  \\t\n    \"\"\"\n    text = re.sub('\\n', ' ', text)\n    text = re.sub('\\t', ' ', text)\n    text = re.sub('\\b', ' ', text)\n    text = re.sub('\\r', ' ', text)\n    return text\n\n\ndef spacing_punctuation(text):\n    \"\"\"\n    add space before and after punctuation and symbols\n    \"\"\"\n    re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤$&#‘’])')\n    return re_tok.sub(r' \\1 ', text)\n\n\ndef remove_punctuation(text):\n    \"\"\"\n    remove punctuation from text\n    \"\"\"\n    re_tok = re.compile(f'([{string.punctuation}])')\n    return re_tok.sub(' ', text)\n\n\ndef spacing_number(text):\n    \"\"\"\n    add space before and after numbers\n    \"\"\"\n    re_tok = re.compile('([0-9]{1,})')\n    return re_tok.sub(r' \\1 ', text)\n\n\ndef decontracted(text):\n    \"\"\"\n    de-contract the contraction\n    \"\"\"\n    # specific\n    text = re.sub(r\"(W|w)on\\'t\", \"will not\", text)\n    text = re.sub(r\"(C|c)an\\'t\", \"can not\", text)\n\n    # general\n    text = re.sub(r\"(I|i)\\'m\", \"i am\", text)\n    text = re.sub(r\"(A|a)in\\'t\", \"is not\", text)\n    text = re.sub(r\"n\\'t\", \" not\", text)\n    text = re.sub(r\"\\'re\", \" are\", text)\n    text = re.sub(r\"\\'s\", \" is\", text)\n    text = re.sub(r\"\\'d\", \" would\", text)\n    text = re.sub(r\"\\'ll\", \" will\", text)\n    text = re.sub(r\"\\'t\", \" not\", text)\n    text = re.sub(r\"\\'ve\", \" have\", text)\n    return text\n\n\ndef clean_number(text):\n    \"\"\"\n    replace number with hash\n    \"\"\"\n    text = re.sub('[0-9]{5,}', '#####', text)\n    text = re.sub('[0-9]{4}', '####', text)\n    text = re.sub('[0-9]{3}', '###', text)\n    text = re.sub('[0-9]{2}', '##', text)\n    return text\n\n\ndef remove_number(text):\n    \"\"\"\n    numbers are not toxic\n    \"\"\"\n    return re.sub('\\d+', ' ', text)\n\n\ndef remove_space(text):\n    \"\"\"\n    remove extra spaces and ending space if any\n    \"\"\"\n    text = re.sub('\\s+', ' ', text)\n    text = re.sub('\\s+$', '', text)\n    return text\ndef cleanHtml(sentence):\n    cleanr = re.compile('<.*?>')\n    cleantext = re.sub(cleanr, ' ', str(sentence))\n    return cleantext\n\n\ndef cleanHtml(sentence):\n    cleanr = re.compile('<.*?>')\n    cleantext = re.sub(cleanr, ' ', str(sentence))\n    return cleantext","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Method used for cleaning\nimport nltk\nfrom nltk.corpus import stopwords\nfrom  nltk.stem import SnowballStemmer\n\nTEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n\n\nstop_words = stopwords.words(\"english\")\nstemmer = SnowballStemmer(\"english\")\ndef preprocess(text, stem=False):\n    # Remove link,user and special characters\n    text = re.sub(TEXT_CLEANING_RE, ' ', str(text).lower()).strip()\n    tokens = []\n    text = spacing_punctuation(text)\n    text = spacing_number(text)\n    text = decontracted(text)\n    text = remove_number(text)\n    text=cleanHtml(text)\n    text = remove_space(text)\n    text = remove_punctuation(text)\n    for token in text.split():\n        if token not in stop_words:\n            if stem:\n                tokens.append(stemmer.stem(token))\n            else:\n                tokens.append(token)\n    return \" \".join(tokens).strip()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n\ndef clean_text(x):\n    x = str(x)\n    for punct in puncts:\n        x = x.replace(punct, f' {punct} ')\n    return x\n\ndef clean_numbers(x):\n    x = re.sub('[0-9]{5,}', '#####', x)\n    x = re.sub('[0-9]{4}', '####', x)\n    x = re.sub('[0-9]{3}', '###', x)\n    x = re.sub('[0-9]{2}', '##', x)\n    return x\n\nmispell_dict = {\"aren't\" : \"are not\",\n\"can't\" : \"cannot\",\n\"couldn't\" : \"could not\",\n\"didn't\" : \"did not\",\n\"doesn't\" : \"does not\",\n\"don't\" : \"do not\",\n\"hadn't\" : \"had not\",\n\"hasn't\" : \"has not\",\n\"haven't\" : \"have not\",\n\"he'd\" : \"he would\",\n\"he'll\" : \"he will\",\n\"he's\" : \"he is\",\n\"i'd\" : \"I would\",\n\"i'd\" : \"I had\",\n\"i'll\" : \"I will\",\n\"i'm\" : \"I am\",\n\"isn't\" : \"is not\",\n\"it's\" : \"it is\",\n\"it'll\":\"it will\",\n\"i've\" : \"I have\",\n\"let's\" : \"let us\",\n\"mightn't\" : \"might not\",\n\"mustn't\" : \"must not\",\n\"shan't\" : \"shall not\",\n\"she'd\" : \"she would\",\n\"she'll\" : \"she will\",\n\"she's\" : \"she is\",\n\"shouldn't\" : \"should not\",\n\"that's\" : \"that is\",\n\"there's\" : \"there is\",\n\"they'd\" : \"they would\",\n\"they'll\" : \"they will\",\n\"they're\" : \"they are\",\n\"they've\" : \"they have\",\n\"we'd\" : \"we would\",\n\"we're\" : \"we are\",\n\"weren't\" : \"were not\",\n\"we've\" : \"we have\",\n\"what'll\" : \"what will\",\n\"what're\" : \"what are\",\n\"what's\" : \"what is\",\n\"what've\" : \"what have\",\n\"where's\" : \"where is\",\n\"who'd\" : \"who would\",\n\"who'll\" : \"who will\",\n\"who're\" : \"who are\",\n\"who's\" : \"who is\",\n\"who've\" : \"who have\",\n\"won't\" : \"will not\",\n\"wouldn't\" : \"would not\",\n\"you'd\" : \"you would\",\n\"you'll\" : \"you will\",\n\"you're\" : \"you are\",\n\"you've\" : \"you have\",\n\"'re\": \" are\",\n\"wasn't\": \"was not\",\n\"we'll\":\" will\",\n\"didn't\": \"did not\",\n\"tryin'\":\"trying\"}\n\ndef _get_mispell(mispell_dict):\n    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n    return mispell_dict, mispell_re\n\nmispellings, mispellings_re = _get_mispell(mispell_dict)\ndef replace_typical_misspell(text):\n    def replace(match):\n        return mispellings[match.group(0)]\n    return mispellings_re.sub(replace, text)\n\ndef text_cleaning(text):\n    text = clean_text(text)\n    text = clean_numbers(text)\n    text = replace_typical_misspell(text)\n    return text\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_1[\"question_text\"]=train_c.apply(lambda x:preprocess(x,stem=True))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_1[\"question_text\"] = train_1[\"question_text\"].apply(text_cleaning)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_1.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets=train_1[\"question_text\"].values.tolist()\ntype(tweets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_list=list(train_1[\"question_text\"])\ntype(df_train_list)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"markdown","source":"#Tokenization\n\nimport nltk\n  \nfrom nltk.tokenize import word_tokenize \ntoken_train=[]\nfor word in df_train_list:\n    x=word_tokenize(word)\n    token_train.append(x)\n"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"token_train"},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.tokenize import RegexpTokenizer\n\ntokenizer = RegexpTokenizer(r'\\w+')\n\ntrain_1[\"tokens\"] = train_1[\"question_text\"].apply(tokenizer.tokenize)\ntrain_1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(train_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_labels=train_1[\"target\"].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(list_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gensim\n\nword2vec_path = \"../input/worl2vec/GoogleNews-vectors-negative300.bin\"\nword2vec = gensim.models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word2vec[\"god\"].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_average_word2vec(tokens_list, vector, generate_missing=False, k=300):\n    if len(tokens_list)<1:\n        return np.zeros(k)\n    if generate_missing:\n        vectorized = [vector[word] if word in vector else np.random.rand(k) for word in tokens_list]\n    else:\n        vectorized = [vector[word] if word in vector else np.zeros(k) for word in tokens_list]\n    length = len(vectorized)\n    summed = np.sum(vectorized, axis=0)\n    averaged = np.divide(summed, length)\n    return averaged\n\ndef get_word2vec_embeddings(vectors, clean_questions, generate_missing=False):\n    embeddings = clean_questions['tokens'].apply(lambda x: get_average_word2vec(x, vectors, \n                                                                                generate_missing=generate_missing))\n    return list(embeddings)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings = get_word2vec_embeddings(word2vec, train_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Data_word=np.array(embeddings)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.savetxt(\"Data_word.txt\", Data_word) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nwith open(\"embedding.txt\", \"wb\") as fp:   #Pickling\n    pickle.dump(embeddings, fp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nwith open(\"list_labels.txt\",\"wb\") as fp:\n    pickle.dump(list_labels,fp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For Word2vec\nfrom sklearn.model_selection import train_test_split\nX_train_word2vec, X_test_word2vec, y_train_word2vec, y_test_word2vec = train_test_split(embeddings, list_labels, \n                                                                                        test_size=0.2, random_state=40)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#For tf idf split dataset into train and test\n\nx_train, x_test,y_train,y_test = train_test_split(nb_tl, y,test_size=0.2, random_state=40)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(y_train_word2vec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(X_train_word2vec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=train_1['target'].values\ntype(y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_W_np=np.array(X_train_word2vec)\ny_train_W_np=np.array(y_train_word2vec)\nX_test_W_np=np.array(X_test_word2vec)\ny_test_W_np=np.array(y_test_word2vec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"from scipy import sparse\nX_train_W_cs=sparse.csr_matrix(X_train_word2vec)\ny_train_W_cs=np.array(y_train_word2vec)\nX_test_W_ncs=sparse.csr_matrix(X_test_word2vec)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"'''\nhttps://dl.acm.org/doi/epdf/10.5555/2390665.2390688\nhttps://marvinlsj.github.io/2018/11/23/NBSVM%20for%20sentiment%20and%20topic%20classification/\n\nLogistic regression with NB log count ratio\n'''\nfrom scipy.sparse import csr_matrix,save_npz,load_npz\np = 1 + X_train_np[y_train_np==1].sum(0)\nq = 1 + X_train_np[y_train_np==0].sum(0)\nr = csr_matrix(np.log((p/(1 + (y_train_np==1).sum()))/(q/(1+ (y_train_np==0).sum()))))"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"def multiply(X,r):\n    return X.dot(r)\n"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# obj= NBTransformer().fit(train,y)\nnb_train=multiply(X_train_np,r)\nnb_test=multiply(X_test_np,r)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scatter graph On Word2Vec\nfrom sklearn.decomposition import PCA, TruncatedSVD\nimport matplotlib\nimport matplotlib.patches as mpatches\n\n\ndef plot_LSA(test_data, test_labels, savepath=\"PCA_demo.csv\", plot=True):\n        lsa = TruncatedSVD(n_components=2)\n        lsa.fit(test_data)\n        \n        lsa_scores = lsa.transform(test_data)\n        # color_mapper = {label:idx for idx,label in enumerate(set(test_labels))}\n        # color_column = [color_mapper[label] for label in test_labels]\n        print(set(test_labels))\n        colors = ['orange','blue','black']\n        if plot:\n            plt.scatter(lsa_scores[:,0], lsa_scores[:,1], s=8, alpha=.8, c=test_labels, cmap=matplotlib.colors.ListedColormap(colors))\n            red_patch = mpatches.Patch(color='orange', label='Zero ')\n            green_patch = mpatches.Patch(color='black', label='One')\n            plt.legend(handles=[red_patch, green_patch], prop={'size': 30})\n\n\nfig = plt.figure(figsize=(16, 16))          \nplot_LSA(embeddings, list_labels)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #Scatter graph On TF-idf\nfig = plt.figure(figsize=(16, 16))          \nplot_LSA(nb_tl, y)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Word2vec Logestic\nclf_w2v = LogisticRegression(C=11.0, class_weight='balanced', solver='newton-cg', \n                         multi_class='multinomial', random_state=40)\nclf_w2v.fit(X_train_word2vec, y_train_word2vec)\ny_predicted_word2vec_demo = clf_w2v.predict(X_test_word2vec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for Tf idf\nclf_w2v = LogisticRegression(C=11.0, class_weight='balanced', solver='newton-cg', \n                         multi_class='multinomial', random_state=40)\nclf_w2v.fit(x_train, y_train)\ny_predicted_demo = clf_w2v.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(y_predicted_word2vec_demo)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n\ndef get_metrics(y_test, y_predicted):  \n    # true positives / (true positives+false positives)\n    precision = precision_score(y_test, y_predicted, pos_label=None,\n                                    average='weighted')             \n    # true positives / (true positives + false negatives)\n    recall = recall_score(y_test, y_predicted, pos_label=None,\n                              average='weighted')\n    \n    # harmonic mean of precision and recall\n    f1 = f1_score(y_test, y_predicted, pos_label=None, average='weighted')\n    \n    # true positives + true negatives/ total\n    accuracy = accuracy_score(y_test, y_predicted)\n    return accuracy, precision, recall, f1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Word2vec Score\naccuracy_word2vec, precision_word2vec, recall_word2vec, f1_word2vec = get_metrics(y_test_word2vec, y_predicted_word2vec_demo)\nprint(\"accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy_word2vec, precision_word2vec, \n                                                                       recall_word2vec, f1_word2vec))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport itertools\nfrom sklearn.metrics import confusion_matrix\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.winter):\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, fontsize=30)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, fontsize=20)\n    plt.yticks(tick_marks, classes, fontsize=20)\n    \n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", \n                 color=\"white\" if cm[i, j] < thresh else \"black\", fontsize=40)\n    \n    plt.tight_layout()\n    plt.ylabel('True label', fontsize=30)\n    plt.xlabel('Predicted label', fontsize=30)\n\n    return plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Word2Vec embedding Confussion Matrix\ncm_w2v = confusion_matrix(y_test_word2vec, y_predicted_word2vec_demo)\nfig = plt.figure(figsize=(10, 10))\nplot = plot_confusion_matrix(cm_w2v, classes=['ZERO','ONE'], normalize=False, title='Confusion matrix')\nplt.show()\nprint(\"Word2Vec confusion matrix\")\nprint(cm_w2v)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tf idf Score\naccuracy_tfidf, precision_tfidf, recall_tfidf, f1_tfidf = get_metrics(y_test, y_predicted_demo)\nprint(\"accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy_tfidf, precision_tfidf, \n                                                                       recall_tfidf, f1_tfidf))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tf idf embedding Confussion Matrix\ncm_tf = confusion_matrix(y_test, y_predicted_demo)\nfig = plt.figure(figsize=(10, 10))\nplot = plot_confusion_matrix(cm_tf, classes=['ZERO','ONE'], normalize=False, title='Confusion matrix')\nplt.show()\nprint(\"Tf-idf confusion matrix\")\nprint(cm_tf)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preprocessing\ntest_1[\"question_text\"]=test_c.apply(lambda x:preprocess(x,stem=True))\ntest_1[\"question_text\"] = test_1[\"question_text\"].apply(text_cleaning)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#tokanize\ntest_1[\"tokens\"] = test_1[\"question_text\"].apply(tokenizer.tokenize)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#embedding\nembeddings_1 = get_word2vec_embeddings(word2vec, test_1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_w2v.fit(embeddings, list_labels)\ny_predicted_word2vec = clf_w2v.predict(embeddings_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(y_predicted_word2vec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission=pd.read_csv('../input/quora1/sample_submission.csv')\nsubmission.drop([\"target\"],axis=1)\nsubmission['target']=y_predicted_word2vec\nsubmission.to_csv('y_predicted_word2vec.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### END","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install catboost\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn import tree\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn import svm\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import confusion_matrix, roc_auc_score ,roc_curve,auc\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.datasets import load_breast_cancer \nfrom sklearn.svm import SVC \n  \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn import tree\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.sparse import csr_matrix,save_npz,load_npz\nnb_tl=load_npz('../input/test-and-train-data/nb_train.npz')\nnb_testl=load_npz('../input/test-and-train-data/nb_test.npz')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dic={'question':nb_tl,'target':Y}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_N=pd.DataFrame(dic)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_N1=train_N.drop(['target'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#split dataset into train and test\n\nx_train, x_test,y_train,y_test = train_test_split(nb_tl, y,test_size=0.2, random_state=40)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LogisticRegression"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression(random_state=1)\nmodel.fit(x_train, y_train)\nmodel.score(x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LogisticRegression on word to vec"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression(random_state=1)\nmodel.fit(X_train_word2vec, y_train_word2vec)\nmodel.score(X_test_word2vec, y_test_word2vec)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hyperparameter tuning on LogisticRegression"},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n\nlogreg_cv=GridSearchCV(cv=None,\n             estimator=LogisticRegression(C=1.0, intercept_scaling=1,   \n               dual=False, fit_intercept=True, penalty='l2', tol=0.0001),\n             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]})\n\nlogreg_cv.fit(nb_tl,y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* ****Best Score**:**  0.9548472379449044\n* ****Best Params**: ** {'C': 1}"},{"metadata":{},"cell_type":"markdown","source":"# SVM"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"model = svm.SVC()\nmodel.fit(x_train, y_train)\nmodel.score(x_test, y_test)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# SVM on wordtovec\nmodel = svm.SVC(kernel='linear')\nmodel.fit(X_train_word2vec, y_train_word2vec)\nmodel.score(X_test_word2vec, y_test_word2vec)"},{"metadata":{},"cell_type":"markdown","source":"## On SVC DID Hyperparameter tuning "},{"metadata":{},"cell_type":"markdown","source":"#LinearScv\nparam_grid = {\n    'C':            [10,40,80],\n    'kernel':       ['linear'],                   # precomputed,'poly', 'sigmoid'\n    'degree':       [3,4],\n    'gamma':        [0.001,0.0001],\n    'shrinking':    [True],\n    'probability':  [False],\n    'cache_size':   [2000],\n    'class_weight': [None],\n    'verbose':      [False],\n    'max_iter':     [-1],\n    'random_state': [None],\n    }\n  \ngrid = RandomizedSearchCV(SVC(), param_grid, refit = True, verbose = 10) \n  \n# fitting the model for grid search \ngrid.fit(nb_tl, y)\nprint('Best Score: ', grid.best_score_)\nprint('Best Params: ', grid.best_params_)"},{"metadata":{},"cell_type":"markdown","source":"# DecisionTree"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"model = tree.DecisionTreeClassifier(random_state=1)\nmodel.fit(x_train, y_train)\nmodel.score(x_test, y_test)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# DecisionTreeTO WORDTOVEC\nmodel = tree.DecisionTreeClassifier(random_state=1)\nmodel.fit(X_train_W_np, y_train_W_np)\nmodel.score(X_test_W_np, y_test_W_np)\n"},{"metadata":{},"cell_type":"markdown","source":"# Hyperparameter tuning on RandomForestClassifie"},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier()\n\nn_estimators = [250,300,350,400]\nmax_depth = [6,7,8]\nparam = dict(n_estimators=n_estimators,\n                  max_depth=max_depth)\n\nrandom = RandomizedSearchCV(estimator=rfc,\n                            param_distributions=param,\n                            scoring='roc_auc',\n                            verbose=100, n_jobs=-1,\n                            n_iter=1000)\nrandom_result = random.fit(nb_tl, y)\n\nprint('Best Score: ', random_result.best_score_)\nprint('Best Params: ', random_result.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Best Score:  0.9139219026051947\n* **Best Params:  {'n_estimators': 400, 'max_depth': 7}"},{"metadata":{"trusted":true},"cell_type":"code","source":"modelr= RandomForestClassifier(n_estimators=400,max_depth=7)\nmodelr.fit(x_train, y_train)\nmodelr.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RandomForestClassifier WORDTOVEC\nmodelr1= RandomForestClassifier(n_estimators=400,max_depth=7)\nmodelr1.fit(X_train_word2vec, y_train_word2vec)\nmodelr1.score(X_test_word2vec, y_test_word2vec)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model= RandomForestClassifier(n_estimators=400,max_depth=7)\nmodel.fit(nb_tl, y)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filename=\"model_random\"\npickle.dump(model,open(filename,'wb'))\nmodel_1 = pickle.load(open(filename, 'rb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_ram=model.predict(nb_testl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsub1=pd.read_csv('../input/quora1/sample_submission.csv')\nsub1.drop([\"target\"],axis=1)\nsub1['target']=pred_ram\nsub1.to_csv('ran_pred1.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XGBClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"modelx=xgb.XGBClassifier(random_state=1,learning_rate=0.15,n_estimators=700)\nmodelx.fit(x_train, y_train)\nmodelx.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelx1=xgb.XGBClassifier(random_state=1,learning_rate=0.15,n_estimators=700)\nmodelx1.fit(X_train_word2vec, y_train_word2vec)\nmodelx1.score(X_test_word2vec, y_test_word2vec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=xgb.XGBClassifier(random_state=1,learning_rate=0.25,n_estimators=1400)\nmodel.fit(nb_tl, y)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = 'XG_model.sav'\npickle.dump(model, open(filename, 'wb'))\n\nloaded_model = pickle.load(open(filename, 'rb'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_xg=model.predict(nb_testl)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub=pd.read_csv('../input/quora/sample_submission.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.drop([\"target\"],axis=1)\nsub['target']=pred_xg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('xg_pred',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hyperparameter tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"#LinearScv\nparam_grid = {'C': [1,100],  \n              'gamma': [0.1, 0.01], \n              'kernel': ['linear'],\n               'degree':[3]}  \n  \ngrid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 10) \n  \n# fitting the model for grid search \ngrid.fit(nb_tl, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_svc=grid.predict(nb_testl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub=pd.read_csv('../input/quora/sample_submission.csv')\nsub.drop([\"target\"],axis=1)\nsub['target']=pred_svc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('pred_svc',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Best Score: ', grid.best_score_)\nprint('Best Params: ', grid.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. # Random Search ON RandomForestClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier()\n\nn_estimators = [350,400,550,600]\nmax_depth = [5,6,7]\nparam = dict(n_estimators=n_estimators,\n                  max_depth=max_depth)\n\nrandom = RandomizedSearchCV(estimator=rfc,\n                            param_distributions=param,\n                            scoring='roc_auc',\n                            verbose=1000, n_jobs=-1,\n                            n_iter=1000)\nrandom_result = random.fit(x_train, y_train)\n\nprint('Best Score: ', random_result.best_score_)\nprint('Best Params: ', random_result.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random Search WORDTOVEC\nrfc = RandomForestClassifier()\n\nn_estimators = [350,400,550,600]\nmax_depth = [6,7,8,9]\nparam = dict(n_estimators=n_estimators,\n                  max_depth=max_depth)\n\nrandom = RandomizedSearchCV(estimator=rfc,\n                            param_distributions=param,\n                            scoring='roc_auc',\n                            verbose=100, n_jobs=-1,\n                            n_iter=1000)\nrandom_result = random.fit(X_train_W_np, y_train_W_np)\n\nprint('Best Score: ', random_result.best_score_)\nprint('Best Params: ', random_result.best_params_)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier()\n\nn_estimators = [200,400,500,600]\nmax_depth = [3,4,7,8,9,10,11,16]\nparam = dict(n_estimators=n_estimators,\n                  max_depth=max_depth)\n\nrandom = RandomizedSearchCV(estimator=rfc,\n                            param_distributions=param,\n                            scoring='roc_auc',\n                            verbose=1000, n_jobs=-1,\n                            n_iter=1000)\nrandom_result = random.fit(nb_tl, y)\n\nprint('Best Score: ', random_result.best_score_)\nprint('Best Params: ', random_result.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = 'ramdomforestbest.sav'\npickle.dump(random, open(filename, 'wb'))\n\nloaded_model = pickle.load(open(filename, 'rb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ramdomforset=random.predict(nb_testl)\nsub=pd.read_csv('../input/quora1/sample_submission.csv')\nsub.drop([\"target\"],axis=1)\nsub['target']=pred_ram\nsub.to_csv('ramdomforset',index=False)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MaxVoting"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel1 = LogisticRegression(C=11.0, intercept_scaling=1,   \n               dual=False, fit_intercept=True, penalty='l2', tol=0.0001)\nmodel2 =  RandomForestClassifier(max_depth=7, n_estimators=400,random_state=0)\nmodel3 = SGDClassifier(random_state=1,alpha=0.05, loss=\"modified_huber\", max_iter=1000, penalty=\"l1\")\nmodel11 = VotingClassifier(estimators=[('lr', model1), ('dt', model2), ('NB', model3)])\nmodel11.fit(x_train,y_train)\nmodel11.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MAx Voting wordtovec\n\nmodel1 = LogisticRegression(C=11.0, intercept_scaling=1,   \n               dual=False, fit_intercept=True, penalty='l2', tol=0.0001)\nmodel2 =  RandomForestClassifier(max_depth=7, n_estimators=400,random_state=0)\nmodel3 = SGDClassifier(random_state=1,alpha=0.05, loss=\"modified_huber\", max_iter=1000, penalty=\"l1\")\nmodel12 = VotingClassifier(estimators=[('lr', model1), ('dt', model2), ('NB', model3)])\nmodel12.fit(X_train_word2vec, y_train_word2vec)\nmodel12.score(X_test_word2vec, y_test_word2vec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# On Main test data we apply ramdom forest\nmodel1 = LogisticRegression(C=11.0, intercept_scaling=1,   \n               dual=False, fit_intercept=True, penalty='l2', tol=0.0001)\nmodel2 =  RandomForestClassifier(max_depth=7, n_estimators=400,random_state=0)\nmodel3 = SGDClassifier(random_state=1,alpha=0.05, loss=\"modified_huber\", max_iter=1000, penalty=\"l1\")\n\n\nmodel_m = VotingClassifier(estimators=[('lr', model1), ('rf', model2), ('NB', model3)])\nmodel_m.fit(nb_tl, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"maxvoting=model_m.predict(nb_testl)\nsubmission['target']=maxvoting\nsubmission.to_csv('maxvoting.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Weighted Averaging"},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = LogisticRegression(C=11.0, intercept_scaling=1,   \n               dual=False, fit_intercept=True, penalty='l2', tol=0.0001)\nmodel2 =  RandomForestClassifier(max_depth=7, n_estimators=400,random_state=0)\nmodel3 = SGDClassifier(random_state=1,alpha=0.05, loss=\"modified_huber\", max_iter=1000, penalty=\"l1\")\n\nmodel1.fit(x_train,y_train)\nmodel2.fit(x_train,y_train)\nmodel3.fit(x_train,y_train)\n\npred1 = model1.predict_proba(x_test)\npred2 = model2.predict_proba(x_test)\npred3 = model3.predict_proba(x_test)\n\nweighted_prediction = (0.7*pred1)+(0.2*pred2)+(0.1*pred3)\nlabelprediction = np.argmax(weighted_prediction, axis = 1)\n\naccuracy_score(labelprediction, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Weighted Averaging wordtovec\nmodel1 = LogisticRegression(C=11.0, intercept_scaling=1,   \n               dual=False, fit_intercept=True, penalty='l2', tol=0.0001)\nmodel2 =  RandomForestClassifier(max_depth=7, n_estimators=400,random_state=0)\nmodel3 = SGDClassifier(random_state=1,alpha=0.05, loss=\"modified_huber\", max_iter=1000, penalty=\"l1\")\n\nmodel1.fit(X_train_word2vec, y_train_word2vec)\nmodel2.fit(X_train_word2vec, y_train_word2vec)\nmodel3.fit(X_train_word2vec, y_train_word2vec)\n\npred1 = model1.predict_proba(X_test_word2vec)\npred2 = model2.predict_proba(X_test_word2vec)\npred3 = model3.predict_proba(X_test_word2vec)\n\nweighted_prediction = (0.7*pred1)+(0.2*pred2)+(0.1*pred3)\nlabelprediction1 = np.argmax(weighted_prediction, axis = 1)\n\naccuracy_score(labelprediction1,y_test_word2vec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Weighted Averaging on main test data\n\nmodel1 = LogisticRegression(C=11.0, intercept_scaling=1,   \n               dual=False, fit_intercept=True, penalty='l2', tol=0.0001)\nmodel2 =  RandomForestClassifier(max_depth=7, n_estimators=400,random_state=0)\nmodel3 = SGDClassifier(random_state=1,alpha=0.05, loss=\"modified_huber\", max_iter=1000, penalty=\"l1\")\n\nmodel1.fit(nb_tl, y)\nmodel2.fit(nb_tl, y)\nmodel3.fit(nb_tl, y)\n\npred1 = model1.predict_proba(nb_testl)\npred2 = model2.predict_proba(nb_testl)\npred3 = model3.predict_proba(nb_testl)\n\nweighted_prediction = (0.7*pred1)+(0.2*pred2)+(0.1*pred3)\nweightedavg = np.argmax(weighted_prediction, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['target']=weightedavg\nsubmission.to_csv('weightedavg.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Stacking"},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = LogisticRegression(C=11.0, intercept_scaling=1,   \n               dual=False, fit_intercept=True, penalty='l2', tol=0.0001)\nmodel2 =  RandomForestClassifier(max_depth=7, n_estimators=400,random_state=0)\nmodel3 = SGDClassifier(random_state=1,alpha=0.05, loss=\"modified_huber\", max_iter=1000, penalty=\"l1\")\n\n\nstack = StackingClassifier(estimators=[('dt',model1),('lr',model2)], final_estimator=model2,cv=10)\nstack.fit(nb_tl,y)\n# stack.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Stacking=stack.predict(nb_testl)\nsubmission['target']=Stacking\nsubmission.to_csv('Stacking.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Blending"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(nb_t1,y, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train, test = train_test_split(train_N, test_size=0.2, random_state=0)\n\n# x_train=train.drop(['target'], axis=1)\n# y_train=train['target']\n\n# x_val=test.drop(['target'], axis=1)\n# y_val=test['target']\n\n# x_val = x_val.reset_index(drop = True)\n# x_test = x_test.reset_index(drop = True)\n\nmodel1 = SGDClassifier(random_state=1, loss=\"modified_huber\", alpha=0.05, max_iter=1000, penalty=\"l1\")\nmodel1.fit(x_train, y_train)\n\nval_pred1=model1.predict(x_test)\ntest_pred1=model1.predict(nb_testl)\n\nval_pred1=pd.DataFrame(val_pred1)\ntest_pred1=pd.DataFrame(test_pred1)\n\nmodel2 =  RandomForestClassifier(max_depth=7, n_estimators=400,random_state=0)\nmodel2.fit(x_train,y_train)\n\nval_pred2=model2.predict(x_test)\ntest_pred2=model2.predict(nb_testl)\n\nval_pred2=pd.DataFrame(val_pred2)\ntest_pred2=pd.DataFrame(test_pred2)\n\nmodel3 = LogisticRegression(C=11.0, intercept_scaling=1,   \n               dual=False, fit_intercept=True, penalty='l2', tol=0.0001)\nmodel3.fit(x_train,y_train)\n\nval_pred3=model3.predict(x_test)\ntest_pred3=model3.predict(nb_testl)\n\nval_pred3=pd.DataFrame(val_pred3)\ntest_pred3=pd.DataFrame(test_pred3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.sparse import hstack\ndf_val=hstack((x_test, val_pred1,val_pred2,val_pred3))\ndf_test = hstack((nb_testl, test_pred1,test_pred2,test_pred3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression(C=11.0, intercept_scaling=1,   \n               dual=False, fit_intercept=True, penalty='l2', tol=0.0001)\nmodel.fit(df_val,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"blending=model.predict(df_test)\nsubmission['target']=blending\nsubmission.to_csv('blending.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#stop word removal\n  \nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\nstopw=set(stopwords.words('english'))\narr0=[]\nfor i in ls1:  \n    filtered_sentence = [w for w in i if not w in stopw] \n    arr0.append(filtered_sentence)\narr=[]                \nbad_word=['~','`','!','@','#','$','%','^','&','*','(',')','_','-','=','+','|',';',':','<','>','.','/','?','[',']','{','}']\nfor y in arr0:\n    lss=[q for q in y if not q in bad_word]\n    arr.append(lss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kaggle competitions submit -c quora -f submission.csv -m \"Message\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#stemming\\lemmataizer\nimport nltk\nnltk.download(\"wordnet\")\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import wordnet\n\ndef get_wordnet_pos(word2):\n    pos=nltk.pos_tag([word2])[0][1][0].upper()\n    word_pos={\n             \"J\": wordnet.ADJ,\n             \"N\": wordnet.NOUN,\n             \"V\": wordnet.VERB,\n             \"R\": wordnet.ADV\n             }\n    return word_pos.get(pos,wordnet.NOUN)\narr1=[]\nobj=WordNetLemmatizer()\nfor i in arr:\n    arr1.append([obj.lemmatize(w,get_wordnet_pos(w)) for w in i])\n\n\n   \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import nltk\nfrom nltk.stem import PorterStemmer\nps = PorterStemmer()\narr3=[]\narr4=[]\nfor array in arr:\n    for w in array:\n        arr3.append(ps.stem(w))\n    arr4.append(arr3) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Word embedding\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nvecterize=TfidfVectorizer()\nvecterize.fit(df_train_list)\n\nvector1=vecterize.transform(df_train_list)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(vector1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vector=np.array(vector1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vector2=vector1.toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(vector)\nvector","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train_s.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Initializing Support Vector Machine and fitting the training data\n\nfrom sklearn.svm import SVC\nclassifier = SVC(kernel='rbf', random_state = 1)\nclassifier.fit(vector1,Y_train_s)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predicting the classes for test set\n\nY_pred = classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Attaching the predictions to test set for comparing\n\ntest_set[\"Predictions\"] = Y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculating the accuracy of the predictions\n\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(Y_test_s,Y_pred)\naccuracy = float(cm.diagonal().sum())/len(Y_test_s)\nprint(\"\\nAccuracy Of SVM For The Given Dataset : \", accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nfrom gensim.models import KeyedVectors\nfrom gensim.models import Word2Vec\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# define training data arr1\n# train model\nmodel = Word2Vec(token_train, min_count=1)\n\n#This is vocabulary of on which the model is train\nwords1=list(model.wv.vocab)\n#choose a arbitary word from the vocabulary\nprint(model['girl'].shape)\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now we do dimensionality reduction on our train model\n#fit 2d pca model to vector\n\n# summarize vocabulary\n\nwords = list(model.wv.vocab)\n# print(new_model)\n# fit a 2d PCA model to the vectors\nX = model[model.wv.vocab]\npca = PCA(n_components=1)\nresult = pca.fit_transform(X)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(result)\nprint(type(result))\nfrom itertools import chain \nresult_list = list(chain.from_iterable(list(result))) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Dict=list(model.wv.vocab)\nprint(Dict)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a scatter plot of the projection\nplt.figure(figsize= (20,20))\nplt.scatter(result[:, 0], result[:, 1])\nwords = list(model.wv.vocab)\nfor i, word in enumerate(words):\n    plt.annotate(word, xy=(result[i, 0], result[i, 1]))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    w1='male'\n    w2='female'\n    w3='queen'\n    r = model.most_similar(positive=[w1, w3], negative=[w2])\n    print(\"%s - %s = %s - %s\" % (w1, w2, r[0][0], w3))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(type(model['dog']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vec_word=list(model.wv.vocab)\n\nWord_dic={k:v for k, v in zip(vec_word,result_list)}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Word_dic","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\n\ntsne = TSNE()\n\n\nnum_of_words = 200\n\n\nZ = tsne.fit_transform(X1[:num_of_words])\nplt.figure(figsize= (20,20))\nplt.scatter(Z[:,0], Z[:,1])\nfor i in range(num_of_words):\n        try:\n            plt.annotate(vec_word[i, xy=(Z[i,0], Z[i,1])\n        except:\n            print(\"bad string:\", X1[i])\nplt.draw()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Loading word vectors...')\nword2vec = {}\nembedding = []\nidx2word = []\nfor line in model:\n    values = line.split()\n    word = values[0]\n    vec = np.asarray(values[1:], dtype='float32')\n    word2vec[word] = vec\n    embedding.append(vec)\n    idx2word.append(word)\nprint('Found %s word vectors.' % len(word2vec))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}